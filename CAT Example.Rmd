---
title: "CAT Equating"
output:
  word_document: default
date: "2024-11-25"
author: "Josiah Hunsberger"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

required_packages <- c("mirt", "mirtCAT", "ggplot2", "dplyr", "openxlsx", "flextable", "parallel", "plyr", "SNSequate")

# Check and install packages if needed
for (pkg in required_packages) {
  if (!requireNamespace(pkg, quietly = TRUE)) {
    install.packages(pkg)
    library(pkg, character.only = TRUE)
  } else {
    library(pkg, character.only = TRUE)
  }
}
```

```{r Inital Phase/Bank Building , echo=FALSE}
nitems <- 60
Persons <- 2000
set.seed(123)

# Person Parmameters
Theta <- matrix(rnorm(Persons))

# Item Parameters
a <- rlnorm(nitems, meanlog = 0.3, sdlog = 0.4)       # Pulling a's from lognormal dist
b <- rnorm(nitems)                                    # M and SD are 0 and 1 by default
c <- rep(0.25, nitems)              

# Combine item parameters into a matrix
item_params <- data.frame(a1 = a, d = -(a*b), g = c)

mirt_object <- generate.mirt_object(parameters = item_params, itemtype = "3PL")

Sim_Responses <- generate_pattern(mirt_object, Theta = Theta)

# Renaming as these will be used as out linking items for all other administrations
Linking_Items <- item_params
Linking_Items$b <- (item_params$d/-(item_params$a))

```


```{r Investigating, echo=FALSE}
#Looking at how our known 60 items would function if applied in a CAT for two examinees - Theta = -0.5605 and 1.5587
pattern <- generate_pattern(mirt_object, Theta = 1)
CAT_1 <- mirtCAT(mo = mirt_object, local_pattern = pattern, start_item = "MI", criteria = "MI")

pattern <- generate_pattern(mirt_object, Theta = 3)
CAT_2 <- mirtCAT(mo = mirt_object, local_pattern = pattern, start_item = "MI", criteria = "MI")

paste0("Theta 1")
print(CAT_1$items_answered)
paste0("Theta 2")
print(CAT_2$items_answered)
```
Do you notice anything about the items administered? Particularly within the first few items?

```{r Investigating v2, echo=FALSE}
paste0("Item difficulties of items: 23, 54, 4, 39, 45, 42, 58, 55, 1")
print(Linking_Items[c(23, 54, 4, 39, 45, 42, 58, 55, 1),4])
```

# CAT Application
```{r Adaptive Cluster, echo=FALSE}
nitems <- 61:1000

# Pulling Item Parameters from the same distributions as above for the Linking items
a <- rlnorm(nitems, meanlog = 0.3, sdlog = 0.4)
b <- rnorm(nitems)
c <- rep(0.25, length(nitems))

# Combine item parameters into a matrix
item_params <- data.frame(a1 = a, d = -(a*b), g = c)

# Renaming as these will be used as out linking items for all other administrations
Adaptive_Items <- item_params
Adaptive_Items$b <- (item_params$d/-(item_params$a))
```

```{r Calibration Cluster, echo=FALSE}
nitems <- 1001:2000

# Pulling Item Parameters from the same distributions as above for the Linking items
a <- rlnorm(nitems, meanlog = 0.3, sdlog = 0.4)
b <- rnorm(nitems)
c <- rep(0.25, length(nitems))

# Combine item parameters into a matrix
item_params <- data.frame(a1 = a, d = -(a*b), g = c)

# Renaming as these will be used as out linking items for all other administrations
Calibration_Items <- item_params
Calibration_Items$b <- (item_params$d/-(item_params$a))
```

```{r Runnign CAT, echo=FALSE}

# Creating the Item Pool
pool <- rbind.fill(Linking_Items[,c(1:3)], Adaptive_Items[,c(1:3)], Calibration_Items[,c(1:3)])

# Generating Simulees for CAT
Theta <- matrix(rnorm(Persons))
CAT_mirt_object <- generate.mirt_object(pool, '3PL')
responses <- generate_pattern(CAT_mirt_object, Theta = Theta)


CAT_Theta <- matrix(rnorm(Persons))
CAT_Responses <- generate_pattern(mirt_object, Theta = CAT_Theta)

content <- c(rep("Linking_Items", 60),
             rep("Adaptive_Items", 940),
             rep("Calibration_Items", 1000))
content_prop <- c("Adaptive_Items" = 0.4,  "Calibration_Items" = 0.4, "Linking_Items" = 0.2)

# Constraining Linking items to item parms from our Fixed Form
params_to_fix <- mod2values(mirt_object)
params_to_fix$est[params_to_fix$item %in% Linking_Items] <- FALSE  
params_to_fix$est[!params_to_fix$item %in% Linking_Items] <- TRUE

cl <- makeCluster(detectCores())
design <- list(min_SEM = .3, min_items = 25, max_items = 100, content = content, content_prop = content_prop)
mirtCAT_results <- mirtCAT(mo = CAT_mirt_object, local_pattern = responses, pars = params_to_fix,
                           start_item = "MI", design = design, cl = cl, criteria = "MI")
stopCluster(cl)
```

```{r Plotting CAT, echo=FALSE}
low <- which.min(Theta)
high <- which.max(Theta)
average <- which.min(abs(Theta))

plot(mirtCAT_results[[low]]) #Lowest Theta
plot(mirtCAT_results[[high]]) #Highest Theta
plot(mirtCAT_results[[average]]) #Average Theta
```
Why might it take more items to reduce the SE of our lowest examinee?

```{r CAT Result Checking, echo=FALSE}
paste0("Person ", which.min(Theta))
print(mirtCAT_results[[low]]$items_answered)
paste0("Number of Link Items administered: ", sum(mirtCAT_results[[low]]$items_answered < 60))
paste0("Propotion of Link Items: ", (sum(mirtCAT_results[[low]]$items_answered < 60)/(length(mirtCAT_results[[low]]$items_answered))))

paste0("Person ", which.max(Theta))
print(mirtCAT_results[[high]]$items_answered)
paste0("Number of Link Items administered: ", sum(mirtCAT_results[[high]]$items_answered < 60))
paste0("Propotion of Link Items: ", (sum(mirtCAT_results[[high]]$items_answered < 60)/(length(mirtCAT_results[[high]]$items_answered))))

paste0("Person ", which.min(abs(Theta)))
print(mirtCAT_results[[average]]$items_answered)
paste0("Number of Link Items administered: ", sum(mirtCAT_results[[average]]$items_answered < 60))
paste0("Propotion of Link Items: ", (sum(mirtCAT_results[[average]]$items_answered < 60)/(length(mirtCAT_results[[average]]$items_answered))))
```
Do you notice anything about the items administered? Particularly within the first few items?

What do you think the item parameters of Item 922 will be?

Why is this different than when we ran CAT on our initial 60 items?

At which point do the tests diverge for our Average (Person 118) vs High (736)? What might have been the cause of that?


```{r Item 862, echo=FALSE}
#Looking at all item parms 
First_Item <- pool[mirtCAT_results[[high]]$items_answered[1],]

First_Item$b <- pool[mirtCAT_results[[high]]$items_answered[1],2]/(-(pool[mirtCAT_results[[high]]$items_answered[1],1]))

flextable(First_Item)
```

Why would we choose this item first?